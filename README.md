# sales_customer
I built a PySpark ETL pipeline that reads raw sales and customer data, applies transformations like joins and aggregations, and writes the processed data in Parquet format. 
